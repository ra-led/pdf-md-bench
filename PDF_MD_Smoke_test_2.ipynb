{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7HU7TF5dAo3"
      },
      "outputs": [],
      "source": [
        "!cd pdfs && unzip -qq pdfs.zip\n",
        "!ls pdfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0elGVgng4LZ"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Peuq6B54FQIw"
      },
      "outputs": [],
      "source": [
        "!pip install -U ms-swift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGcoHUsWEgNn"
      },
      "outputs": [],
      "source": [
        "!pip install flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIQiSQmPg4La"
      },
      "outputs": [],
      "source": [
        "!pip install decord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN6LTz-MF0Ax"
      },
      "outputs": [],
      "source": [
        "!pip install pypdfium2 qwen-vl-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceNPEEdsg4La"
      },
      "outputs": [],
      "source": [
        "!pip install vllm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVWxRtWTg4La"
      },
      "outputs": [],
      "source": [
        "!pip install \"numpy<2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj3ygf55Fy70"
      },
      "outputs": [],
      "source": [
        "from pypdfium2 import PdfDocument\n",
        "\n",
        "\n",
        "def convert_pdf_to_images(pdf_path, scale=1.0):\n",
        "    pdf_document = PdfDocument(pdf_path)\n",
        "    pages = []\n",
        "    for page_index in range(len(pdf_document)):\n",
        "        page = pdf_document[page_index]\n",
        "        pil_image = page.render(scale=scale).to_pil()\n",
        "        pages.append(pil_image)\n",
        "        page.close()\n",
        "\n",
        "    pdf_document.close()\n",
        "\n",
        "    return pages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkPKJSWcYmT8"
      },
      "source": [
        "# HF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjSBAVPIg4Lb"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.57.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXWwd8qyD-42"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_path = 'baidu/ERNIE-4.5-VL-28B-A3B-PT'\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    dtype=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)\n",
        "processor.eval()\n",
        "model.add_image_preprocess(processor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bN277liEWst"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "SYSTEM_PROMPT = \"You are helpful assistant.\"\n",
        "\n",
        "INSTRUCTIONS = \"\"\"Covetr this page image to specific markdown\n",
        "\n",
        "---\n",
        "\n",
        "1) Output format\n",
        "\n",
        "- Output must be Markdown, ordered in natural human reading order.\n",
        "- Use '#' to represent heading levels ('#', '##', '###', etc). Keep titles and section headers with correct hierarchy.\n",
        "- Preserve paragraphs as continuous text blocks.\n",
        "- Use '-' for bulleted lists.\n",
        "- Use '1.', '2.', '3.' for numbered lists.\n",
        "- Tables MUST be represented strictly in HTML.\n",
        "- Preserve original text and number formatting exactly.\n",
        "- Ignore page headers and footers unless semantically meaningful.\n",
        "\n",
        "---\n",
        "\n",
        "2) Universal image region tagging (MANDATORY)\n",
        "\n",
        "- For EVERY image-like region (drawings, photos, charts, diagrams, stamps, logos):\n",
        "  - Output exactly:\n",
        "    <img data-bbox=\"x1 y1 x2 y2\">DESCRIPTION</img>\n",
        "- Use a nearby caption if present; otherwise a short factual description.\n",
        "- Place <img> tags in reading order.\n",
        "\n",
        "---\n",
        "\n",
        "Answer only with extracted content in described format without any comments and additions\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def build_messages() -> list[dict]:\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": SYSTEM_PROMPT},\n",
        "            ],\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"image\": \"tmp.png\",\n",
        "                },\n",
        "                {\"type\": \"text\", \"text\": INSTRUCTIONS},\n",
        "            ],\n",
        "        }\n",
        "    ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDLI6y5lg4Lc"
      },
      "outputs": [],
      "source": [
        "images_dir = Path('page_images')\n",
        "dataset_path = Path('dataset.jsonl')\n",
        "\n",
        "records = []\n",
        "for pdf_path in tqdm(Path('pdfs').glob('*.pdf')):\n",
        "    pages = convert_pdf_to_images(pdf_path, scale=1.0)\n",
        "    for i, p in enumerate(pages):\n",
        "        sample_path = images_dir / pdf_path.stem\n",
        "        image_path = sample_path / f'{i}.png'\n",
        "        sample_path.mkdir(parents=True, exist_ok=True)\n",
        "        page_w, page_h = p.size\n",
        "        p.save('tmp.png')\n",
        "\n",
        "        messages = build_messages()\n",
        "        text = processor.apply_chat_template(\n",
        "            messages, tokenize=False, add_generation_prompt=True, enable_thinking=False\n",
        "        )\n",
        "        image_inputs, video_inputs = processor.process_vision_info(messages)\n",
        "        inputs = processor(\n",
        "            text=[text],\n",
        "            images=image_inputs,\n",
        "            videos=video_inputs,\n",
        "            padding=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        # Inference: Generation of the output\n",
        "        device = next(model.parameters()).device\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        generated_ids = model.generate(\n",
        "            inputs=inputs['input_ids'].to(device),\n",
        "            **inputs,\n",
        "            max_new_tokens=5000\n",
        "            )\n",
        "        output_text = processor.decode(generated_ids[0])\n",
        "\n",
        "        record = {\n",
        "            \"page_w\": page_w,\n",
        "            \"page_h\": page_h,\n",
        "            \"page\": i,\n",
        "            \"messages\": messages,\n",
        "            \"images\": [image_path.absolute().as_posix()],\n",
        "            \"response\": output_text\n",
        "        }\n",
        "        records.append(record)\n",
        "\n",
        "with open(\"resilts-ernie.jsonl\", \"w\", encoding=\"utf-8\") as handle:\n",
        "    for record in records:\n",
        "        handle.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxMzDc5dYu9c"
      },
      "source": [
        "# MS-SWIFT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjKxLOqtNVol"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "SYSTEM_PROMPT = \"You are helpful assistant.\"\n",
        "\n",
        "INSTRUCTIONS = \"\"\"Covetr this page image to specific markdown\n",
        "\n",
        "---\n",
        "\n",
        "1) Output format\n",
        "\n",
        "- Output must be Markdown, ordered in natural human reading order.\n",
        "- Use '#' to represent heading levels ('#', '##', '###', etc). Keep titles and section headers with correct hierarchy.\n",
        "- Preserve paragraphs as continuous text blocks.\n",
        "- Use '-' for bulleted lists.\n",
        "- Use '1.', '2.', '3.' for numbered lists.\n",
        "- Tables MUST be represented strictly in HTML.\n",
        "- Preserve original text and number formatting exactly.\n",
        "- Ignore page headers and footers unless semantically meaningful.\n",
        "\n",
        "---\n",
        "\n",
        "2) Universal image region tagging (MANDATORY)\n",
        "\n",
        "- For EVERY image-like region (drawings, photos, charts, diagrams, stamps, logos):\n",
        "  - Output exactly:\n",
        "    <img data-bbox=\"x1 y1 x2 y2\">DESCRIPTION</img>\n",
        "- Use a nearby caption if present; otherwise a short factual description.\n",
        "- Place <img> tags in reading order.\n",
        "\n",
        "---\n",
        "\n",
        "3) ENGINEERING DRAWINGS\n",
        "\n",
        "If an engineering drawing or technical scheme is present, add drawing metadata:\n",
        "\n",
        "Detailed description\n",
        "- 1-2 sentences to describe drawing content\n",
        "\n",
        "Pictures:\n",
        "- Provide drawing bbox: [x1, y1, x2, y2] for all views in \"bbox_2d\" field with view name\n",
        "\n",
        "Legend (if present):\n",
        "- write it in JSON format\n",
        "\n",
        "Dimensions (if present):\n",
        "- write it in JSON format\n",
        "- map dimention values to elemnt name\n",
        "\n",
        "For example:\n",
        "{\n",
        "  \"description\": \"Чертеж описывает дисковый поворотный затвор с ручным редуктором и удлинением штока.\n",
        "  Наименование: Затвор дисковый поворотный DN200 PN1,0 МПа.\n",
        "  Модель/Код: КМЗ-СА-ЗД-12-0200-11.\n",
        "  Рабочее давление: PN 1,0 МПа.\n",
        "  Температурный режим: В тексте указано «от 60 до 100 °С» , однако наличие исполнения УХЛ3 и использование стали 09Г2С обычно подразумевает работу при температурах от -60°С.\n",
        "  Герметичность: Класс «А» по ГОСТ 9544-2015.\n",
        "  Климатическое исполнение: УХЛ3 (для умеренного и холодного климата).\n",
        "  Управление: Ручной редуктор.\n",
        "  Комплектация: Поставляется в комплекте с ответными фланцами, прокладками и крепежом.\n",
        "  Стандарты:\n",
        "  Строительная длина: ASME B16.10.\n",
        "  Конструкция соответствует стандартам ASME и EN 593.\n",
        "  Испытания на огнестойкость: ISO 5208.\n",
        "  ТУ: 28.14.11-001-88287357-2024.\"\n",
        "  \"views\": [\n",
        "    {\"bbox_2d\": [74, 361, 324, 808], \"name\": \"front\"}\n",
        "  ],\n",
        "  \"legend\": {\n",
        "    \"1\":  \"Корпус  09Г2С (Конструкционная низколегированная сталь)\",\n",
        "    \"2\":  \"Седло  09Г2С\",\n",
        "    \"3\":  \"Диск  A182 F304 (Нержавеющая сталь)\",\n",
        "    \"4\":  \"Вал  A182 F316 (Нержавеющая сталь)\",\n",
        "    \"5\":  \"Уплотнение вала  Графит\",\n",
        "    \"6\":  \"Крышка корпуса  09Г2С\",\n",
        "    \"7\":  \"Болт  A193 B8\"\n",
        "  },\n",
        "  \"dimensions\": {\n",
        "    \"DN (Номинальный диаметр)\": \"200 мм\",\n",
        "    \"L (Строительная длина)\": \"88,5 мм\",\n",
        "    \"H (Общая высота)\": \"1440 мм\",\n",
        "    \"H1 (Высота до оси/центра)\": \"726 мм\",\n",
        "    \"Высота удлинительной колонны\": \"810 мм\"\n",
        "  }\n",
        "}\n",
        "---\n",
        "\n",
        "Answer only with extracted content in described format without any comments and additions\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def build_messages() -> list[dict]:\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": INSTRUCTIONS + \"<image>\"},\n",
        "    ]\n",
        "\n",
        "\n",
        "images_dir = Path('page_images')\n",
        "dataset_path = Path('dataset.jsonl')\n",
        "\n",
        "records = []\n",
        "for pdf_path in Path('pdfs').glob('*.pdf'):\n",
        "    pages = convert_pdf_to_images(pdf_path, scale=1.0)\n",
        "    for i, p in enumerate(pages):\n",
        "        sample_path = images_dir / pdf_path.stem\n",
        "        image_path = sample_path / f'{i}.png'\n",
        "        sample_path.mkdir(parents=True, exist_ok=True)\n",
        "        page_w, page_h = p.size\n",
        "        p.save(image_path)\n",
        "\n",
        "        record = {\n",
        "            \"page_w\": page_w,\n",
        "            \"page_h\": page_h,\n",
        "            \"page\": i,\n",
        "            \"messages\": build_messages(),\n",
        "            \"images\": [{\"path\": image_path.absolute().as_posix()}],\n",
        "        }\n",
        "        records.append(record)\n",
        "\n",
        "with dataset_path.open(\"w\", encoding=\"utf-8\") as handle:\n",
        "    for record in records:\n",
        "        handle.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gv79uvS7bbsA"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"qwen\": {\n",
        "        \"chkp\": \"Qwen/Qwen3-VL-30B-A3B-Instruct\",\n",
        "        \"reqs\": 'pip install transformers==4.57.3',\n",
        "        \"hf\": True,\n",
        "        \"attn\": \"flash_attn\",\n",
        "        \"backend\": \"vllm\"\n",
        "    },\n",
        "    \"glm\": {\n",
        "        \"chkp\": \"zai-org/GLM-4.6V-Flash\",\n",
        "        \"reqs\": 'pip install \"transformers>=5.0.0rc0\"',\n",
        "        \"hf\": True,\n",
        "        \"attn\": \"flash_attn\",\n",
        "        \"backend\": \"vllm\"\n",
        "    },\n",
        "    \"internvl\": {\n",
        "        \"chkp\": \"OpenGVLab/InternVL3-14B-Instruct\",\n",
        "        \"reqs\": 'pip install transformers==4.57.3',\n",
        "        \"hf\": True,\n",
        "        \"attn\": \"flash_attn\",\n",
        "        \"backend\": \"vllm\"\n",
        "    },\n",
        "    \"mistral\": {\n",
        "        \"chkp\": \"mistralai/Ministral-3-14B-Instruct-2512-BF16\",\n",
        "        \"reqs\": 'pip install \"transformers>=5.0.0.dev0\" \"mistral-common>=1.8.6\"',\n",
        "        \"hf\": True,\n",
        "        \"attn\": \"flash_attn\",\n",
        "        \"backend\": \"pt\"\n",
        "    },\n",
        "    \"gemma\": {\n",
        "        \"chkp\": \"LLM-Research/gemma-3-27b-it\",\n",
        "        \"reqs\": 'pip install transformers==4.57.3',\n",
        "        \"hf\": False,\n",
        "        \"attn\": \"flash_attn\",\n",
        "        \"backend\": \"vllm\"\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcXvLAAmcPRn"
      },
      "outputs": [],
      "source": [
        "for model_name, meta in models.items():\n",
        "    chkp = meta[\"chkp\"]\n",
        "    use_hf = meta[\"hf\"]\n",
        "    reqs = meta[\"reqs\"]\n",
        "    attn = meta[\"attn\"]\n",
        "    backend = meta[\"backend\"]\n",
        "    if backend == \"vllm\":\n",
        "        print(f'''!{reqs} && CUDA_VISIBLE_DEVICES=0 \\\n",
        "        VLLM_ALLOW_LONG_MAX_MODEL_LEN=1 \\\n",
        "        swift infer \\\n",
        "            --model {chkp} \\\n",
        "            --infer_backend vllm \\\n",
        "            --temperature 0.3 \\\n",
        "            --num_beams 2 \\\n",
        "            --attn_impl {attn} \\\n",
        "            --vllm_gpu_memory_utilization 0.9 \\\n",
        "            --vllm_max_model_len 32768 \\\n",
        "            --val_dataset {dataset_path.absolute().as_posix()} \\\n",
        "            --max_new_tokens 5000 \\\n",
        "            --result_path results-{model_name}.jsonl \\\n",
        "            {\"--use_hf=1\" if use_hf else \"\"}\n",
        "        ''')\n",
        "    elif backend == \"pt\":\n",
        "        print(f'''!{reqs} && CUDA_VISIBLE_DEVICES=0 \\\n",
        "        swift infer \\\n",
        "            --model {chkp} \\\n",
        "            --torch_dtype bfloat16 \\\n",
        "            --infer_backend pt \\\n",
        "            --max_batch_size 16 \\\n",
        "            --temperature 0.3 \\\n",
        "            --num_beams 2 \\\n",
        "            --attn_impl {attn} \\\n",
        "            --val_dataset {dataset_path.absolute().as_posix()} \\\n",
        "            --max_new_tokens 5000 \\\n",
        "            --result_path results-{model_name}.jsonl \\\n",
        "            {\"--use_hf=1\" if use_hf else \"\"}\n",
        "        ''')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPHmfKB-g4Ld"
      },
      "source": [
        "# Postprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_iT3Sthg4Ld"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQ1kDy58g4Ld"
      },
      "outputs": [],
      "source": [
        "def replace_img_tags_with_cropped_images(\n",
        "    markdown_content: str,\n",
        "    page_image_path: str | Path,\n",
        "    page_num: int,\n",
        "    output_path: Path,\n",
        "    normalize_factor: float | None = None\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Replace <img ... data-bbox=\"x1 y1 x2 y2\">desc</img>\n",
        "    with ![desc](./images/filename.png) and save cropped images.\n",
        "    \"\"\"\n",
        "\n",
        "    output_path = Path(output_path)\n",
        "    cropped_dir = output_path / \"images\"\n",
        "    cropped_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    page_image_path = Path(page_image_path)\n",
        "\n",
        "    # Flexible matching: any attributes, any whitespace/newlines in inner text\n",
        "    img_pattern = re.compile(\n",
        "        r'<img\\b[^>]*\\bdata-bbox=\"([^\"]+)\"[^>]*>(.*?)</img>',\n",
        "        re.IGNORECASE | re.DOTALL\n",
        "    )\n",
        "\n",
        "    img_counter = 0\n",
        "\n",
        "    def replace_img_tag(match: re.Match) -> str:\n",
        "        nonlocal img_counter\n",
        "        bbox_str = match.group(1).strip()\n",
        "        description = re.sub(r\"\\s+\", \" \", match.group(2).strip())\n",
        "\n",
        "        # Parse bbox coordinates\n",
        "        try:\n",
        "            parts = re.split(r\"[,\\s]+\", bbox_str)\n",
        "            bbox_values = [float(p) for p in parts if p]\n",
        "            if len(bbox_values) != 4:\n",
        "                return match.group(0)\n",
        "\n",
        "            x1, y1, x2, y2 = bbox_values\n",
        "\n",
        "            if not page_image_path.exists():\n",
        "                # Can't crop if file not found\n",
        "                return match.group(0)\n",
        "\n",
        "            with Image.open(page_image_path) as img:\n",
        "                width, height = img.size\n",
        "\n",
        "                if normalize_factor is not None:\n",
        "                    x1, y1, x2, y2 = [c / normalize_factor for c in (x1, y1, x2, y2)]\n",
        "\n",
        "                # normalized 0..1 coords\n",
        "                if max(x1, y1, x2, y2) <= 1.0:\n",
        "                    x1, x2 = x1 * width, x2 * width\n",
        "                    y1, y2 = y1 * height, y2 * height\n",
        "\n",
        "                # Clamp and convert\n",
        "                x1i, y1i = max(0, int(round(x1))), max(0, int(round(y1)))\n",
        "                x2i, y2i = min(width, int(round(x2))), min(height, int(round(y2)))\n",
        "\n",
        "                if x2i <= x1i or y2i <= y1i:\n",
        "                    return match.group(0)\n",
        "\n",
        "                cropped_img = img.crop((x1i, y1i, x2i, y2i))\n",
        "\n",
        "                img_counter += 1\n",
        "                crop_filename = f\"page_{page_num:03d}_img_{img_counter:02d}.png\"\n",
        "                crop_path = cropped_dir / crop_filename\n",
        "                cropped_img.save(crop_path)\n",
        "\n",
        "                rel_path = f\"./images/{crop_filename}\"\n",
        "                return f\"![{description}]({rel_path})\"\n",
        "\n",
        "        except Exception:\n",
        "            return match.group(0)\n",
        "\n",
        "    return img_pattern.sub(replace_img_tag, markdown_content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tz7eGPkug4Ld"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def clean_markdown_response(response):\n",
        "    # GLM response\n",
        "    start_i = response.find('<|begin') + 16\n",
        "    end_i = response.find('<|end')\n",
        "    response = response[start_i: end_i]\n",
        "\n",
        "    response = response.strip()\n",
        "    if response.startswith(\"```markdown\"):\n",
        "        response = response[11:].strip()\n",
        "    if response.startswith(\"```\"):\n",
        "        response = response[3:].strip()\n",
        "    if response.endswith(\"```\"):\n",
        "        response = response[:-3].strip()\n",
        "    return response\n",
        "\n",
        "\n",
        "def process_jsonl_file(jsonl_path, outpu_dir, normalize_factor):\n",
        "    documents = defaultdict(list)\n",
        "\n",
        "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
        "        for line_num, line in enumerate(f, 1):\n",
        "            record = json.loads(line.strip())\n",
        "            response = record[\"response\"]\n",
        "\n",
        "            if not response:\n",
        "                continue\n",
        "\n",
        "            cleaned_response = clean_markdown_response(response)\n",
        "\n",
        "            images = record[\"images\"]\n",
        "            if not images:\n",
        "                continue\n",
        "\n",
        "            image_path = images[0][\"path\"]\n",
        "            if not image_path:\n",
        "                continue\n",
        "\n",
        "            # Parse path structure\n",
        "            pdf_file_stem, page_filename = image_path.split('/')[-2:]\n",
        "            page_num = int(page_filename.replace('.png', ''))\n",
        "\n",
        "            # Process image tags in the markdown\n",
        "            processed_response = replace_img_tags_with_cropped_images(\n",
        "                cleaned_response,\n",
        "                image_path,\n",
        "                page_num,\n",
        "                output_path=outpu_dir / pdf_file_stem,\n",
        "                normalize_factor=normalize_factor\n",
        "            )\n",
        "            documents[pdf_file_stem].append({\n",
        "                'page_num': page_num,\n",
        "                'content': processed_response\n",
        "            })\n",
        "\n",
        "    # Create markdown files\n",
        "    for pdf_file_stem, pages in documents.items():\n",
        "        pages.sort(key=lambda x: x['page_num'])\n",
        "        full_markdown = \"\\n\\n\".join(page['content'] for page in pages)\n",
        "        md_dir = outpu_dir / pdf_file_stem\n",
        "        md_dir.mkdir(parents=True, exist_ok=True)\n",
        "        md_filename = md_dir / f\"{pdf_file_stem}.md\"\n",
        "\n",
        "        with open(md_filename, 'w', encoding='utf-8') as md_file:\n",
        "            md_file.write(full_markdown)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRvBfqLBg4Ld"
      },
      "outputs": [],
      "source": [
        "for model_name, meta in models.items():\n",
        "    print(model_name)\n",
        "    jsonl_file = Path(f\"results-{model_name}.jsonl\")\n",
        "    outpu_dir = Path(model_name)\n",
        "    normalize_factor = 1000\n",
        "\n",
        "    process_jsonl_file(jsonl_file, outpu_dir, normalize_factor)\n",
        "    !zip -qq -r {model_name}.zip {model_name}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GeJVF0qg4Ld"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}